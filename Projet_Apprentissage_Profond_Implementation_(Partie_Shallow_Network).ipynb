{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCAtqh4go3N8"
   },
   "source": [
    "# Projet - Apprentissage Profond - Implémentation (Partie Shallow Network)\n",
    "\n",
    "**EL KAAKOUR Ahmad & Matthieu RANDRIANTSOA**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Ce notebook contient toutes les fonctions d'implémentation de nos modèles. Il est conçu de sorte à s'exécuter sequentiellement."
   ],
   "metadata": {
    "id": "5c9IDJuWFq-q"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zg5Grcs5IPBt",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:23:19.379106Z",
     "start_time": "2024-10-15T19:23:09.616865Z"
    }
   },
   "source": [
    "import gzip, numpy, torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "id": "9RRIMxO_eyQU",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:24:53.627062Z",
     "start_time": "2024-10-15T19:24:53.617062Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tbtfr35kzBHD"
   },
   "source": [
    "# Partie 2 : ShallowNetwork"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 5 # nombre de données lues à chaque fois\n",
    "nb_epochs = 10 # nombre de fois que la base de données sera lue\n",
    "eta = 0.00001 # taux d'apprentissage\n",
    "w_min = -0.001\n",
    "w_max = 0.001"
   ],
   "metadata": {
    "id": "FqrHYQXoABEZ",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:27.993078Z",
     "start_time": "2024-10-15T19:25:27.984073Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FayEbNOlpI2T"
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:15:54.604773Z",
     "start_time": "2024-09-16T21:15:53.228364Z"
    },
    "id": "kz6BRjxbIaV-"
   },
   "outputs": [],
   "source": [
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('data/mnist.pkl.gz'), weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OJPz93Kqyhf"
   },
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T21:15:55.491111Z",
     "start_time": "2024-09-16T21:15:55.471604Z"
    },
    "id": "-jzPKy96q1Xz"
   },
   "outputs": [],
   "source": [
    "training_dataset = torch.utils.data.TensorDataset(data_train, label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test, label_test)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lcq2K9L-RnVV"
   },
   "source": [
    "## Création du modèle de réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F56u7edkzET_",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:27:10.076402Z",
     "start_time": "2024-10-15T19:27:10.064402Z"
    }
   },
   "source": [
    "class ShallowNetwork(torch.nn.Module):\n",
    "    def __init__(self, nb_of_neurons):\n",
    "        super(ShallowNetwork, self).__init__()\n",
    "\n",
    "        self.hidden_layer = torch.nn.Linear(28 * 28, nb_of_neurons)  # Entrées MNIST de taille 28x28\n",
    "        self.output_layer = torch.nn.Linear(nb_of_neurons, 10)  # 10 classes MNIST (digits 0-9)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = torch.nn.functional.relu(x)  # fonction d'activation pour introduire de la non-linearité\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnS4dtdF2eML"
   },
   "source": [
    "## Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:26:18.277029Z",
     "start_time": "2024-09-13T09:26:18.269178Z"
    },
    "id": "WN3ooLfIMB2h"
   },
   "outputs": [],
   "source": [
    "shallowNetworkModel = ShallowNetwork(100)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss() # Fonction coût utilisé pour la classification multi-classes\n",
    "optim = torch.optim.SGD(shallowNetworkModel.parameters(), lr = 0.1)"
   ],
   "metadata": {
    "id": "I3CDFnsEZDeg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:28:50.907282Z",
     "start_time": "2024-09-13T09:26:20.122171Z"
    },
    "id": "yVJVqdPx1UfO",
    "outputId": "54283362-8d08-4d83-f05a-aacc3342e773",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loss: 0.000504723924677819, Accuracy: [0.93685716]\n",
      "Loss: 0.12743769586086273, Accuracy: [0.9352857]\n",
      "Loss: 0.000931544229388237, Accuracy: [0.939]\n",
      "Loss: 0.6536549925804138, Accuracy: [0.93871427]\n",
      "Loss: 0.055088337510824203, Accuracy: [0.94214284]\n",
      "Loss: 3.492635726928711, Accuracy: [0.9392857]\n",
      "Loss: 0.14079053699970245, Accuracy: [0.94]\n",
      "Loss: 0.005089778918772936, Accuracy: [0.938]\n",
      "Loss: 0.001042656716890633, Accuracy: [0.93814284]\n",
      "Loss: 1.5437995195388794, Accuracy: [0.94285715]\n"
     ]
    }
   ],
   "source": [
    "for n in range(nb_epochs):\n",
    "    shallowNetworkModel.train() # Set model to training mode\n",
    "    for x,t in training_loader:\n",
    "\n",
    "        y = shallowNetworkModel(x)\n",
    "\n",
    "        loss = loss_func(y, t) # Compare les prédictions y aux vraies valeurs t\n",
    "        optim.zero_grad()\n",
    "        loss.backward() # Calcul le gradient de la perte par rapport aux paramètres du modèles\n",
    "        optim.step() #\n",
    "\n",
    "    acc = 0\n",
    "    shallowNetworkModel.eval()                      # Set model to evaluation mode\n",
    "    with torch.inference_mode():                    # Disable gradient computation for testing\n",
    "        for data, target in test_loader:\n",
    "            outputs = shallowNetworkModel(data)\n",
    "\n",
    "            loss = loss_func(outputs, target)\n",
    "            acc += torch.argmax(outputs,1) == torch.argmax(target,1)\n",
    "\n",
    "    print(f\"Loss: {loss}, Accuracy: {(acc/data_test.shape[0]).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKc-J2tSRnVX"
   },
   "source": [
    "## Enregistrer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T07:04:49.218301Z",
     "start_time": "2024-09-12T07:04:49.206885Z"
    },
    "id": "k-PD00JSRnVX",
    "outputId": "cfefd772-3104-4b9e-f4c8-7cda94fddd47",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving model to: models/shallow_network_130924CEL.pth\n"
     ]
    }
   ],
   "source": [
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"shallow_network_130924CEL.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=shallowNetworkModel.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Tjb9jMn2gNx"
   },
   "source": [
    "## Évaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T12:34:53.552260Z",
     "start_time": "2024-09-15T12:34:53.518533Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rbxBpJd2ork",
    "outputId": "423ab95c-35b1-4744-c3f3-c9a09c15eb66"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy: 94.28571319580078%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "\n",
    "shallowNetworkModel.eval()                           # Set model to evaluation mode\n",
    "with torch.inference_mode():                    # Disable gradient computation for testing\n",
    "    for data, target in test_loader:\n",
    "        outputs = shallowNetworkModel(data)\n",
    "        correct += torch.argmax(outputs,1) == torch.argmax(target,1)\n",
    "\n",
    "accuracy = 100 * correct/data_test.shape[0]\n",
    "print(f'Test Accuracy: {accuracy.numpy().item()}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7zKmuALRnVY"
   },
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VRpFMXW2RnVY",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:07.259389Z",
     "start_time": "2024-10-15T19:25:07.242387Z"
    }
   },
   "source": [
    "def train_and_evaluate(_model, _training_loader, _validation_loader, _params, device='cpu'):\n",
    "    \"\"\"\n",
    "    Entraîne et évalue un modèle d'apprentissage automatique ou d'apprentissage profond.\n",
    "\n",
    "    Paramètres:\n",
    "      ----------\n",
    "      _model : torch.nn.Module\n",
    "          Le modèle à entraîner et à évaluer. Cela doit être un modèle PyTorch.\n",
    "\n",
    "      _training_loader : torch.utils.data.DataLoader\n",
    "          DataLoader pour le jeu de données d'entraînement, fournissant des lots de données à utiliser pour l'entraînement du modèle.\n",
    "\n",
    "      _validation_loader : torch.utils.data.DataLoader\n",
    "          DataLoader pour le jeu de données de validation, fournissant des lots de données pour évaluer le modèle après chaque époque.\n",
    "\n",
    "      _params : dict\n",
    "          Un dictionnaire contenant les hyperparamètres du modèle, comme le taux d'apprentissage, le nombre d'époques, et autres configurations spécifiques.\n",
    "\n",
    "      device : str, optionnel\n",
    "          L'appareil sur lequel exécuter le modèle (par exemple 'cpu' ou 'cuda' pour un GPU). Par défaut 'cpu'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extraire les hyperparamètres depuis params\n",
    "    _nb_epochs = _params.get('nb_epochs', 10)\n",
    "    _loss_func = _params.get('loss_func', torch.nn.CrossEntropyLoss())\n",
    "    _optim = _params.get('optimizer', torch.optim.SGD(_model.parameters(), lr=_params.get('learning_rate', 0.001)))\n",
    "\n",
    "    # Déplacer le modèle vers le périphérique spécifié (GPU si disponible)\n",
    "    _model.to(device)\n",
    "\n",
    "    # Initialiser des listes pour suivre les pertes et les précisions afin d'analyser les performances\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    # Boucle d'entraînement\n",
    "    for epoch in range(_nb_epochs):\n",
    "        _model.train()  # Mettre le modèle en mode entraînement\n",
    "        epoch_training_loss = 0.0\n",
    "\n",
    "        # Étape d'entraînement\n",
    "        for x, t in _training_loader:\n",
    "            x, t = x.to(device), t.to(device)  # Déplacer les données vers le périphérique\n",
    "\n",
    "            # Passer en avant (forward pass)\n",
    "            y = _model(x)\n",
    "\n",
    "            # Calculer la perte\n",
    "            _loss = _loss_func(y, t)\n",
    "            epoch_training_loss += _loss.item()\n",
    "\n",
    "            # Rétropropagation et optimisation\n",
    "            _optim.zero_grad()  # Réinitialiser les gradients\n",
    "            _loss.backward()  # Calculer les gradients\n",
    "            _optim.step()  # Mettre à jour les poids du modèle\n",
    "\n",
    "        # Perte moyenne d'entraînement pour l'époque\n",
    "        avg_training_loss = epoch_training_loss / len(_training_loader)\n",
    "        training_losses.append(avg_training_loss)\n",
    "\n",
    "        # Étape de validation\n",
    "        _model.eval()  # Mettre le modèle en mode évaluation\n",
    "        epoch_val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        # Désactiver le calcul des gradients pendant l'évaluation\n",
    "        with torch.inference_mode():\n",
    "            for data, target in _validation_loader:  # Utiliser validation_loader pour la validation\n",
    "                data, target = data.to(device), target.to(device)  # Déplacer les données vers le périphérique\n",
    "\n",
    "                # Passer en avant (forward pass)\n",
    "                outputs = _model(data)\n",
    "\n",
    "                # Calculer la perte\n",
    "                _loss = _loss_func(outputs, target)\n",
    "                epoch_val_loss += _loss.item()\n",
    "\n",
    "                # Calculer la précision\n",
    "                predicted_labels = torch.argmax(outputs, dim=1)\n",
    "                true_labels = torch.argmax(target, dim=1)\n",
    "                correct_predictions += (predicted_labels == true_labels).sum().item()\n",
    "                total_predictions += target.size(0)\n",
    "\n",
    "        # Perte moyenne de validation et précision pour l'époque\n",
    "        avg_val_loss = epoch_val_loss / len(_validation_loader)\n",
    "        validation_losses.append(avg_val_loss)\n",
    "\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        validation_accuracies.append(accuracy)\n",
    "\n",
    "        # Afficher les métriques pour l'époque en cours\n",
    "        print(f\"Époque {epoch + 1}/{nb_epochs}, Validation loss: {avg_val_loss:.4f}, Validation accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Calcul de la précision finale sur le jeu de test\n",
    "    final_correct_predictions = 0\n",
    "    final_total_predictions = 0\n",
    "\n",
    "    _model.eval()  # Mettre le modèle en mode évaluation\n",
    "    with torch.inference_mode():\n",
    "        for data, target in _validation_loader:  # Utiliser test_loader pour la phase finale de test\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = _model(data)\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            true_labels = torch.argmax(target, dim=1)\n",
    "            final_correct_predictions += (predicted_labels == true_labels).sum().item()\n",
    "            final_total_predictions += target.size(0)\n",
    "\n",
    "    # Calculer la précision finale sur le jeu de test\n",
    "    final_test_accuracy = final_correct_predictions / final_total_predictions\n",
    "    print(f\"Précision finale: {final_test_accuracy:.4f}\")\n",
    "\n",
    "    # Retourner les métriques de performance pour analyse ultérieure\n",
    "    return {\n",
    "        'hyperparameters': _params,\n",
    "        'training_losses': training_losses,\n",
    "        'validation_losses': validation_losses,\n",
    "        'validation_accuracies': validation_accuracies,\n",
    "        'final_validation_accuracy': final_test_accuracy\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L9U7w3Q6RnVa",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:08.976269Z",
     "start_time": "2024-10-15T19:25:08.963248Z"
    }
   },
   "source": [
    "def setup_and_train(_params, device='cpu'):\n",
    "    \"\"\"\n",
    "    Prépare les données, les loader et le paramétrage du modèle. Puis lance l'entrainement et l'évaluation du modèle\n",
    "    \"\"\"\n",
    "    _batch_size = _params.get('batch_size', 64)\n",
    "    _nb_neurons = _params.get('nb_neurons', 10)\n",
    "\n",
    "    # Create Loader\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    _model = ShallowNetwork(_nb_neurons)\n",
    "\n",
    "    # Call training function\n",
    "    print(f\"Training the model : {_params.get('learning_rate', 0.001 ), _batch_size, nb_epochs, _nb_neurons}\")\n",
    "    return train_and_evaluate(_model, train_loader, val_loader, _params, device)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Méthodologie pour trouver les bons hyperparamètres"
   ],
   "metadata": {
    "id": "KruCQHf1eDcI"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-uVE-PMRnVa"
   },
   "source": [
    "### **Étape 1** : Préparation du jeu de validation"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('data/mnist.pkl.gz'))\n",
    "training_dataset = torch.utils.data.TensorDataset(data_train, label_train)\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRLUBkwNt-EC",
    "outputId": "a127fcbc-102e-47f8-aa44-7621963faef1",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:37.916503Z",
     "start_time": "2024-10-15T19:25:37.456032Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "enQ59QOPRnVa",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:45.634918Z",
     "start_time": "2024-10-15T19:25:45.606475Z"
    }
   },
   "source": [
    "# Diviser le jeu de données en sous-ensembles\n",
    "generator = torch.Generator().manual_seed(42) # Permet de reproduire le même découpement\n",
    "train_subset, val_subset = torch.utils.data.random_split(training_dataset, [0.8, 0.2], generator=generator)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fClMs1EDRnVb",
    "outputId": "879241a1-260c-4345-ef99-937aafe7adb5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:49.664063Z",
     "start_time": "2024-10-15T19:25:49.658040Z"
    }
   },
   "source": [
    "print(len(train_subset), len(val_subset))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50400 12600\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWI9CieGRnVb"
   },
   "source": [
    "## **Étape 2** : Définir les hyperparamètres et définir une plage de valeurs à explorer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PuzmTnu3RnVc",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:52.134615Z",
     "start_time": "2024-10-15T19:25:52.120612Z"
    }
   },
   "source": [
    "param_grid = {\n",
    "    \"learning_rate_range\" :  [0.1, 0.01, 0.001, 0.0001],\n",
    "    \"batch_size_range\" : [4, 8, 16, 32, 64, 128],\n",
    "    \"nb_epochs_range\" :  [10, 20, 50, 100],\n",
    "    \"nb_neurones_range\" :  [10, 25, 50, 100]\n",
    "}\n",
    "\n",
    "# Créer toutes les combinaisons de paramètres possibles\n",
    "param_combinations = list(itertools.product(param_grid['learning_rate_range'],\n",
    "                                            param_grid['batch_size_range'],\n",
    "                                            param_grid['nb_epochs_range'],\n",
    "                                            param_grid['nb_neurones_range'])\n",
    "                          )"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7aFAOk9RnVd"
   },
   "source": [
    "## **Étape 3** : Choisir une méthode d’optimisation des hyperparamètres (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-16T21:17:10.588470Z"
    },
    "id": "dL60a-BQRnVe",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Chemin vers le fichier de sortie\n",
    "file_path = \"data/model_metrics_1809024_follow_up.json\"\n",
    "\n",
    "# Vérifie si le fichier existe déjà pour savoir si c'est le premier ajout\n",
    "first_write = not os.path.exists(file_path)\n",
    "\n",
    "res = []\n",
    "\n",
    "# Ouvre le fichier en mode ajout (append) pour écrire progressivement les résultats\n",
    "with open(file_path, \"a\") as json_file:\n",
    "\n",
    "    # Si c'est la première écriture, on ouvre un tableau JSON avec un crochet ouvrant\n",
    "    if first_write:\n",
    "        json_file.write(\"[\\n\")  # Début de l'array JSON\n",
    "\n",
    "    # Boucle sur toutes les combinaisons d'hyperparamètres\n",
    "    for i, (lr, batch_size, nb_epochs, hidden_units) in enumerate(param_combinations):\n",
    "\n",
    "        # Calcule les résultats pour les hyperparamètres actuels\n",
    "        result = setup_and_train(_params={\n",
    "            \"batch_size\": batch_size,\n",
    "            \"nb_epochs\": nb_epochs,\n",
    "            \"learning_rate\": lr,\n",
    "            \"nb_neurons\": hidden_units\n",
    "        },\n",
    "                      device=device)\n",
    "\n",
    "        #\n",
    "        res.append(result)\n",
    "\n",
    "        # Écrit les résultats au format JSON dans le fichier\n",
    "        json.dump(result, json_file)\n",
    "\n",
    "        # Ajoute une virgule et un saut de ligne après chaque entrée, sauf la dernière\n",
    "        if i < len(param_combinations) - 1:\n",
    "            json_file.write(\",\\n\")\n",
    "\n",
    "    # Si c'est la première écriture, on ferme le tableau avec un crochet fermant après la boucle\n",
    "    if first_write:\n",
    "        json_file.write(\"\\n]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test final"
   ],
   "metadata": {
    "id": "q0J-7mDm0gEK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Params\n",
    "_nb_neurons = 100\n",
    "_nb_epochs = 50\n",
    "_batch_size = 8\n",
    "_learning_rate = 0.1\n",
    "\n",
    "# Load data\n",
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('data/mnist.pkl.gz'), weights_only=False)\n",
    "training_dataset = torch.utils.data.TensorDataset(data_train, label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test, label_test)\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "generator = torch.Generator().manual_seed(42) # Permet de reproduire le même découpement\n",
    "train_subset, val_subset = torch.utils.data.random_split(training_dataset, [0.8, 0.2], generator=generator)\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "model = ShallowNetwork(_nb_neurons)\n",
    "\n",
    "#\n",
    "_loss_func = torch.nn.CrossEntropyLoss()\n",
    "_optimizer = torch.optim.SGD(model.parameters(), lr=_learning_rate)\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(_nb_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for x, t in train_loader:\n",
    "        x, t = x.to(device), t.to(device)  # Move data to device\n",
    "\n",
    "        # Forward pass\n",
    "        y = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = _loss_func(y, t)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        _optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        _optimizer.step()  # Update model weights\n",
    "\n",
    "    # Validation step (optional)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.inference_mode():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = _loss_func(outputs, target)\n",
    "\n",
    "# save model\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"shallow_network_130924CEL.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)\n",
    "\n",
    "acc = 0.\n",
    "# on lit toutes les donnéees de test\n",
    "for x,t in test_loader:\n",
    "  # on calcule la sortie du modèle\n",
    "  y = model(x)\n",
    "  # on regarde si la sortie est correcte\n",
    "  acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "# on affiche le pourcentage de bonnes réponses\n",
    "print(acc/data_test.shape[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E70elxeouYjT",
    "outputId": "5a4e885d-e928-482e-9222-c1b86b453cac",
    "ExecuteTime": {
     "end_time": "2024-10-15T19:30:48.885798Z",
     "start_time": "2024-10-15T19:27:14.354430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models\\shallow_network_130924CEL.pth\n",
      "tensor([0.9831])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:37:40.346462Z",
     "start_time": "2024-10-15T19:37:40.330023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = ShallowNetwork(_nb_neurons)\n",
    "model.load_state_dict(torch.load(\"models/model_shallow_network.pth\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:37:42.626987Z",
     "start_time": "2024-10-15T19:37:41.332768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "\n",
    "model.eval()                           # Set model to evaluation mode\n",
    "with torch.inference_mode():                    # Disable gradient computation for testing\n",
    "    for data, target in test_loader:\n",
    "        outputs = model(data)\n",
    "        correct += torch.argmax(outputs,1) == torch.argmax(target,1)\n",
    "        \n",
    "accuracy = 100 * correct/data_test.shape[0]\n",
    "print(f'Test Accuracy: {accuracy.numpy().item()}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.31428527832031%\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
